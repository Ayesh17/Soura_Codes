{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "#import sklearn.cross_validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import ensemble\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras \n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,Bidirectional\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras \n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import Merge\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,Bidirectional,concatenate\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('/Users/s0c02nj/Desktop/c3cc8568-0-dataset/train.csv')\n",
    "test=pd.read_csv('/Users/s0c02nj/Desktop/c3cc8568-0-dataset/test.csv')\n",
    "sample_submission=pd.read_csv('/Users/s0c02nj/Desktop/c3cc8568-0-dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy=train.drop(['Complaint-Status'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining Available Columns in Test and Train for Pre-processing\n",
    "join=train_copy.append(test,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date Time\n",
    "join['Date-received'] =  pd.to_datetime(join['Date-received'], format='%m/%d/%Y')\n",
    "join['Date-sent-to-company'] =  pd.to_datetime(join['Date-sent-to-company'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "join['diff_time']=join['Date-sent-to-company']-join['Date-received']\n",
    "join['diff_time']=join['diff_time'].apply(lambda x:x.days )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Imputing Missing Values for two columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a Separate category for missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Company Respose\n",
    "join['Company-response'].fillna(value='No response',inplace =True)\n",
    "\n",
    "#Missing Dispute-- No Dispute\n",
    "join['Consumer-disputes'].fillna(value=join['Consumer-disputes'].value_counts().index[0],inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "count_trans=len(join['Transaction-Type'].unique())\n",
    "print count_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "count_complain_reason=len(join['Complaint-reason'].unique())\n",
    "print count_complain_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "count_company_response=len(join['Company-response'].unique())\n",
    "print count_company_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_time=np.array(join['diff_time']).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s0c02nj/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "enc_time=scaler.fit_transform(diff_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing The categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Label Encoding the Categorical Varaible----TransactionType\n",
    "le1= preprocessing.LabelEncoder()\n",
    "enc_trans_type=le1.fit_transform(join['Transaction-Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Label Encoding the Categorical Varaible----Complaint-reason\n",
    "le2= preprocessing.LabelEncoder()\n",
    "enc_complain_reason=le2.fit_transform(join['Complaint-reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Label Encoding the Categorical Varaible----Company-response\n",
    "le3= preprocessing.LabelEncoder()\n",
    "enc_comp_response=le3.fit_transform(join['Company-response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.Label Encoding the Categorical Varaible----Consumer-disputes\n",
    "le4= preprocessing.LabelEncoder()\n",
    "enc_cons_dispute=le4.fit_transform(join['Consumer-disputes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response \n",
    "le5= preprocessing.LabelEncoder()\n",
    "y_cat=le5.fit_transform(train['Complaint-Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_enc=to_categorical(y_cat,num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the Text Data Column----> Consumer-complaint-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "join['Consumer-complaint-summary'] = join['Consumer-complaint-summary'].apply(lambda x: re.sub(r'[^a-zA-Z]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "join['Consumer-complaint-summary'] = join['Consumer-complaint-summary'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "join['Consumer-complaint-summary']=join['Consumer-complaint-summary'].str.replace('XX','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "join['Consumer-complaint-summary']=join['Consumer-complaint-summary'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english',max_df=1.0, min_df=1, max_features=50000)\n",
    "tf_feat = vectorizer.fit_transform(join['Consumer-complaint-summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "tf_idf_arr= tf_feat.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Inputs for our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transaction\n",
    "enc_trans_type_train=enc_trans_type[0:43266]\n",
    "enc_trans_type_test=enc_trans_type[43266:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complaint reason\n",
    "enc_complain_reason_train=enc_complain_reason[0:43266]\n",
    "enc_complain_reason_test=enc_complain_reason[43266:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_comp_response_train=enc_comp_response[0:43266]\n",
    "enc_comp_response_test= enc_comp_response[43266:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_cons_dispute_train=enc_cons_dispute[0:43266]\n",
    "enc_cons_dispute_test= enc_cons_dispute[43266:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_time_train=enc_time[0:43266]\n",
    "enc_time_test=enc_time[43266:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_arr_train=tf_idf_arr[0:43266]\n",
    "tf_idf_arr_test=tf_idf_arr[43266:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep():\n",
    "    \n",
    "    #Defining the input-----> Transaction\n",
    "    inputs1 = Input(shape=(1,))\n",
    "    layer_transaction = Embedding(count_trans ,5,input_length=1,trainable=True)(inputs1)\n",
    "    layer_transaction = Flatten()(layer_transaction)\n",
    "    \n",
    "    #Defining the input-----> Complaint-reason\n",
    "    inputs2 = Input(shape=(1,))\n",
    "    layer_complain_reason = Embedding(count_complain_reason ,50,input_length=1,trainable=True)(inputs2)\n",
    "    layer_complain_reason = Flatten()(layer_complain_reason)\n",
    "    \n",
    "    #Defining the input-----> Complaint-reason\n",
    "    inputs3 = Input(shape=(1,))\n",
    "    layer_company_response = Embedding(count_company_response ,3,input_length=1,trainable=True)(inputs3)\n",
    "    layer_company_response = Flatten()(layer_company_response)\n",
    "    \n",
    "    #Defining the input-----> Consumer-disputes\n",
    "    inputs4 = Input(shape=(1,))\n",
    "    layer_consumer_disputes = Embedding(2 ,1,input_length=1,trainable=True)(inputs4)\n",
    "    layer_consumer_disputes = Flatten()(layer_consumer_disputes)\n",
    "    \n",
    "    #Defining the input ----> Time\n",
    "    inputs5 = Input(shape=(1,))\n",
    "    \n",
    "    #Defining the input-----> Consumer-complaint-summary\n",
    "    inputs6 = Input(shape=(50000,))\n",
    "    \n",
    "    #Merge,Cocatenating the inputes\n",
    "    layer_merge= concatenate([layer_transaction, layer_complain_reason, \n",
    "                              layer_company_response,layer_consumer_disputes,inputs5,inputs6])\n",
    "    \n",
    "    #Dense Layers\n",
    "    layer_dense = Dense(5000, activation='relu')(layer_merge)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    \n",
    "    #Dense Layers\n",
    "    layer_dense = Dense(500, activation='relu')(layer_merge)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "   \n",
    "\n",
    "    #Output Layer\n",
    "    probabilities = Dense(5,activation='softmax')(layer_dense)\n",
    "\n",
    "    model = Model(inputs=[inputs1,inputs2,inputs3,inputs4,inputs5,inputs6],outputs=probabilities)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_43 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_44 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_45 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 1, 5)         90          input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_30 (Embedding)        (None, 1, 50)        7600        input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 1, 3)         33          input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_32 (Embedding)        (None, 1, 1)         2           input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 5)            0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 50)           0           embedding_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 3)            0           embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 1)            0           embedding_32[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           (None, 50000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 50060)        0           flatten_29[0][0]                 \n",
      "                                                                 flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "                                                                 input_47[0][0]                   \n",
      "                                                                 input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 500)          25030500    concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 500)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 5)            2505        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 25,040,730\n",
      "Trainable params: 25,040,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=model_deep()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = Adam(lr=0.001), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38939 samples, validate on 4327 samples\n",
      "Epoch 1/4\n",
      "38939/38939 [==============================] - 134s 3ms/step - loss: 0.8178 - acc: 0.7834 - val_loss: 0.6401 - val_acc: 0.7959\n",
      "Epoch 2/4\n",
      "38939/38939 [==============================] - 122s 3ms/step - loss: 0.5970 - acc: 0.7978 - val_loss: 0.6041 - val_acc: 0.7939\n",
      "Epoch 3/4\n",
      "38939/38939 [==============================] - 145s 4ms/step - loss: 0.5295 - acc: 0.8084 - val_loss: 0.5920 - val_acc: 0.7964\n",
      "Epoch 4/4\n",
      "38939/38939 [==============================] - 149s 4ms/step - loss: 0.4662 - acc: 0.8271 - val_loss: 0.5981 - val_acc: 0.7950\n"
     ]
    }
   ],
   "source": [
    "#Deep Learning Model\n",
    "history = model.fit([enc_trans_type_train,\n",
    "                     enc_complain_reason_train,\n",
    "                     enc_comp_response_train,\n",
    "                     enc_cons_dispute_train,\n",
    "                     enc_time_train,\n",
    "                     tf_idf_arr_train] ,y_enc, batch_size = 512, epochs = 4, validation_split=0.1, \n",
    "                     verbose = 1)\n",
    "                    \n",
    "                    #class_weight = {0:0.25 ,1:0.01 ,2:0.25 ,3:0.24 ,4:0.25 })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tets\n",
    "y_prob = model.predict([enc_trans_type_test,enc_complain_reason_test,\n",
    "                     enc_comp_response_test,enc_cons_dispute_test,enc_time_test,tf_idf_arr_test]) \n",
    "\n",
    "#Pred\n",
    "y_classes = y_prob.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s0c02nj/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred=list(le5.inverse_transform(y_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame()\n",
    "submission['Complaint-ID']=test['Complaint-ID']\n",
    "submission['Complaint-Status']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path_or_buf=\"/Users/s0c02nj/Desktop/Submission_deep.csv\", encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    34300\n",
       "3     5018\n",
       "2     2818\n",
       "0      809\n",
       "4      321\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_cat).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Closed with explanation            34300\n",
       "Closed with non-monetary relief     5018\n",
       "Closed with monetary relief         2818\n",
       "Closed                               809\n",
       "Untimely response                    321\n",
       "Name: Complaint-Status, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Complaint-Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
