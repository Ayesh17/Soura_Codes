{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "#import sklearn.cross_validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import ensemble\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras \n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,Bidirectional\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import Permute\n",
    "from keras.layers import merge\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import multiply\n",
    "from keras.layers import concatenate\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test and Train Data\n",
    "train = pd.read_csv(\"/Users/s0c02nj/Desktop/DataQuora//train.csv\",encoding=\"utf-8\")\n",
    "test = pd.read_csv(\"/Users/s0c02nj/Desktop/DataQuora//test.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission File\n",
    "sub = pd.read_csv('/Users/s0c02nj/Desktop/DataQuora//sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00014894849d00ba98a9</td>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000156468431f09b3cae</td>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000227734433360e1aae</td>\n",
       "      <td>What are the best made pocket knives under $20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0005e06fbe3045bd2a92</td>\n",
       "      <td>Why would they add a hypothetical scenario tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00068a0f7f41f50fc399</td>\n",
       "      <td>What is the dresscode for Techmahindra freshers?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  00014894849d00ba98a9  My voice range is A2-C5. My chest voice goes u...\n",
       "1  000156468431f09b3cae           How much does a tutor earn in Bangalore?\n",
       "2  000227734433360e1aae  What are the best made pocket knives under $20...\n",
       "3  0005e06fbe3045bd2a92  Why would they add a hypothetical scenario tha...\n",
       "4  00068a0f7f41f50fc399   What is the dresscode for Techmahindra freshers?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1225312\n",
       "1      80810\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting the no of zeros and ones\n",
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of words for train \n",
    "train_count=[]\n",
    "for i in train['question_text'] :\n",
    "    cnt=len(i)\n",
    "    train_count.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_count)\n",
    "plt.xlim(0,300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of words for test \n",
    "test_count=[]\n",
    "for i in test['question_text'] :\n",
    "    cnt=len(i)\n",
    "    test_count.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_count)\n",
    "plt.xlim(0,300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    #print(\"{:-<40} {}\".format(sentence, str(score)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has the United States become the largest dictatorship in the world? {'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'compound': 0.4215}\n"
     ]
    }
   ],
   "source": [
    "a=sentiment_analyzer_scores(\"Has the United States become the largest dictatorship in the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.326, 'pos': 0.674, 'compound': 0.7351}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg=[]\n",
    "neu=[]\n",
    "pos=[]\n",
    "comp=[]\n",
    "for i in train['question_text'] :\n",
    "    sent=sentiment_analyzer_scores(i)\n",
    "    neg.append(sent['neg'])\n",
    "    neu.append(sent['neu'])\n",
    "    pos.append(sent['pos'])\n",
    "    comp.append(sent['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Negative Sentiment']= neg\n",
    "train['Positive Sentiment']= pos\n",
    "train['Neutral Sentiment']= neu\n",
    "train['Compound Sentiment']= comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg=np.reshape(neg,(-1,1))\n",
    "pos=np.reshape(pos,(-1,1))\n",
    "neu=np.reshape(neu,(-1,1))\n",
    "comp=np.reshape(comp,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>Negative Sentiment</th>\n",
       "      <th>Positive Sentiment</th>\n",
       "      <th>Neutral Sentiment</th>\n",
       "      <th>Compound Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  Negative Sentiment  Positive Sentiment  Neutral Sentiment  \\\n",
       "0       0                 0.0               0.000              1.000   \n",
       "1       0                 0.0               0.263              0.737   \n",
       "2       0                 0.0               0.000              1.000   \n",
       "3       0                 0.0               0.000              1.000   \n",
       "4       0                 0.0               0.000              1.000   \n",
       "\n",
       "   Compound Sentiment  \n",
       "0              0.0000  \n",
       "1              0.6124  \n",
       "2              0.0000  \n",
       "3              0.0000  \n",
       "4              0.0000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg=train[train['target']==0]\n",
    "train_pos=train[train['target']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_sample=train_neg[1:245062]\n",
    "train_sampled = pd.concat((train_neg_sample,train_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    245061\n",
       "1     80810\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the text\n",
    "max_features = 50000\n",
    "tokenizer = Tokenizer(lower = True, filters='', num_words=max_features)\n",
    "full_text = list(train['question_text'].values) + list(test['question_text'].values)\n",
    "tokenizer.fit_on_texts(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the documents---- convert to strings\n",
    "train_tokenized = tokenizer.texts_to_sequences(train['question_text'].fillna('missing'))\n",
    "test_tokenized = tokenizer.texts_to_sequences(test['question_text'].fillna('missing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding the same\n",
    "max_len = 70\n",
    "X_train = pad_sequences(train_tokenized, maxlen = max_len,padding='pre')\n",
    "X_test = pad_sequences(test_tokenized, maxlen = max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "#y_ohe = ohe.fit_transform(train['target'].values.reshape(-1, 1))\n",
    "y= keras.utils.to_categorical(train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 462675 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "#word_index is dictionary of the words and the sequence\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path= '/Users/s0c02nj/Downloads/glove.6B/glove.6B.50d.txt'\n",
    "f=open(folder_path)\n",
    "doc=f.readlines()\n",
    "#****VIP\n",
    "#**WORD TO VEC DICTIONARY\n",
    "#Forming a dictionary-word2vec\n",
    "word2vec={}\n",
    "key=[]\n",
    "#looping though the doc.in the doc the entire thing is saved and is separated by a space bar.\n",
    "for line in doc:\n",
    "    #parts contains every word separately for doc1\n",
    "    parts=line.split(' ')\n",
    "    #part[0] contains the word\n",
    "    word=parts[0]\n",
    "    key.append(word)\n",
    "    #embed contains the vector\n",
    "    embed=np.array(parts[1:],dtype='float32')\n",
    "    #filling up the dictionary\n",
    "    word2vec[word]=embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 1\n"
     ]
    }
   ],
   "source": [
    "#Embedding matrix creation\n",
    "nb_words = min(max_features, len(word_index)+1)\n",
    "embedding_matrix = np.zeros((nb_words, 50))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    #print i\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    if word in word2vec:\n",
    "        embedding_vector = word2vec[word]\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', \n",
    "                      embeddings_regularizer=None, activity_regularizer=None, \n",
    "                      embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "\n",
    "input_length: Length of input sequences, when it is constant.\n",
    "\n",
    "2D tensor with shape: (batch_size, sequence_length).\n",
    "\n",
    "\n",
    "3D tensor with shape: (batch_size, sequence_length, output_dim).\n",
    "embedding_matrix.shape\n",
    "\n",
    "nb_wordsEMBEDDING_DIM\n",
    "\n",
    "Embedding(vocabulary_size, 50, input_length=200, weights=[embedding_matrix], trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_bilstm():\n",
    "#     inputs = Input(shape=(max_len,))\n",
    "#     layer =  Embedding(max_features ,50,input_length=max_len,trainable=False,weights = [embedding_matrix])(inputs)\n",
    "#     layer =  Bidirectional(LSTM(64,return_sequences=False))(layer)\n",
    "#     layer=   Dense(16, activation=\"relu\")(layer)\n",
    "#     layer=   Dropout(0.1)(layer)\n",
    "#     layer =  Dense(2,name='out_layer',activation='sigmoid')(layer)\n",
    "    \n",
    "#     model =  Model(inputs=inputs,outputs=layer)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape: A shape tuple (integers), not including the batch size. For instance, shape=(32,) \n",
    "indicates that the expected input will be batches of 32-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_attn_bilstm():\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    layer =  Embedding(max_features ,50,input_length=max_len,trainable=False,weights = [embedding_matrix])(inputs)\n",
    "    layer =  Bidirectional(LSTM(64,return_sequences=True))(layer)\n",
    "    \n",
    "    #Attention\n",
    "    activations_weights = Dense(1, activation='tanh')(layer)\n",
    "    activations_weights = Flatten()(activations_weights)\n",
    "    activations_weights = Activation('softmax')(activations_weights)\n",
    "    activations_weights = RepeatVector(128)(activations_weights)\n",
    "    activations_weights = Permute([2, 1])(activations_weights)\n",
    "    activations_weighted = multiply([layer, activations_weights])\n",
    "    sent_representation = Lambda(lambda x: K.sum(x, axis=-2))(activations_weighted)\n",
    "    \n",
    "    #Defining inputs for sentiment scores\n",
    "    input_neg=Input(shape=(1,))\n",
    "    input_pos=Input(shape=(1,))\n",
    "    input_neu=Input(shape=(1,))\n",
    "    input_comp=Input(shape=(1,))\n",
    "    \n",
    "    #Concatenating\n",
    "    layer_sentiment = concatenate([sent_representation,input_neg,input_pos,input_neu,input_comp],axis=1)\n",
    "    \n",
    "    #Dense Layer\n",
    "    layer_sentiment= Dense(20, activation='tanh')(layer_sentiment)\n",
    "    \n",
    "    #Output Layer\n",
    "    probabilities = Dense(2,activation='softmax')(layer_sentiment)\n",
    "\n",
    "    model = Model(inputs=[inputs,input_neg,input_pos,input_neu,input_comp],outputs=probabilities)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 70)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 70, 50)       2500000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 70, 128)      58880       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 70, 1)        129         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 70)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 70)           0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 128, 70)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 70, 128)      0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 70, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 132)          0           lambda_1[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           2660        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            42          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,561,711\n",
      "Trainable params: 61,711\n",
      "Non-trainable params: 2,500,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= model_attn_bilstm()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 994s 845us/step - loss: 0.1484 - acc: 0.9463 - val_loss: 0.1327 - val_acc: 0.9500\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 1000s 850us/step - loss: 0.1283 - acc: 0.9517 - val_loss: 0.1264 - val_acc: 0.9520\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train,neg,pos,neu,comp] ,y, batch_size = 512, epochs = 2, validation_split=0.1, \n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - 7s 122us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test, batch_size = 1024, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.round(np.argmax(pred, axis=1)).astype(int)\n",
    "sub['prediction'] = predictions\n",
    "sub.to_csv(\"/Users/s0c02nj/Desktop/Data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
