{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:03<00:00, 24.65it/s]\n"
     ]
    }
   ],
   "source": [
    "covid_path = '/kaggle/input/kaggle-covid-xray/kaggle_covid/covid/'\n",
    "covid_files = os.listdir(covid_path)\n",
    "#covid_files.remove('.DS_Store')\n",
    "\n",
    "labels_covid = []\n",
    "data_covid = []\n",
    "\n",
    "for file in tqdm(covid_files):\n",
    "    imagePath = covid_path + file\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    data_covid.append(image)\n",
    "    labels_covid.append('covid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 85.70it/s]\n"
     ]
    }
   ],
   "source": [
    "pne_path = '/kaggle/input/kaggle-covid-xray/kaggle_covid/pneumonia/'\n",
    "pne_files = os.listdir(pne_path)\n",
    "#norm_files.remove('.DS_Store')\n",
    "\n",
    "labels_pne = []\n",
    "\n",
    "data_pne = []\n",
    "\n",
    "for file in tqdm(pne_files):\n",
    "    imagePath = pne_path + file\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    data_pne.append(image)\n",
    "    labels_pne.append('pneum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_path = '/kaggle/input/kaggle-covid-xray/kaggle_covid/normal/'\n",
    "norm_files = os.listdir(norm_path)\n",
    "#norm_files.remove('.DS_Store')\n",
    "\n",
    "labels_norm = []\n",
    "\n",
    "data_norm = []\n",
    "\n",
    "for file in tqdm(norm_files):\n",
    "    imagePath = norm_path + file\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    data_norm.append(image)\n",
    "    labels_norm.append('normal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_covid + data_pne + data_norm\n",
    "# labels = labels_covid + labels_pne + labels_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate=0.001\n",
    "    drop=0.1\n",
    "    epochs_drop=10\n",
    "    lrate=initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels); print(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.inverse_transform([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=keras.callbacks.LearningRateScheduler(step_decay,verbose=1)\n",
    "\n",
    "\n",
    "trainAug = ImageDataGenerator(rotation_range=15,\n",
    "                              fill_mode=\"nearest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Downloading the Pre-trained Model\n",
    "#mobnet_model = keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "baseModel = keras.applications.VGG16(weights=\"imagenet\", \n",
    "                                     include_top= False,\n",
    "                                     input_tensor=Input(shape=(224, 224, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(64, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.4)(headModel)\n",
    "headModel = Dense(3, activation=\"softmax\")(headModel)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers[:-2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_opt = 6e-4\n",
    "epochs = 10\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=lr_opt, decay= lr_opt / epochs)\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr=keras.callbacks.LearningRateScheduler(step_decay,verbose=1)\n",
    "lr=keras.callbacks.LearningRateScheduler(step_decay,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint= keras.callbacks.ModelCheckpoint('./Checkpoint_normal', monitor='val_acc', \n",
    "                                               verbose=0, save_best_only=True, \n",
    "                                               save_weights_only=False, \n",
    "                                               mode='auto',\n",
    "                                               period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] training head...\")\n",
    "\n",
    "history = model.fit_generator(\n",
    "                trainAug.flow(np.array(trainX), np.array(trainY), batch_size=batch_size),\n",
    "                steps_per_epoch=len(trainX) // batch_size,\n",
    "                validation_data=(np.array(testX), np.array(testY),),\n",
    "                validation_steps=len(testX) // batch_size,\n",
    "                callbacks=[checkpoint,lr],\n",
    "                epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 10), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 10), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 10), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 10), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Plotting Loss and Accuracy on COVID-19 Image Dataset\")\n",
    "plt.xlabel(\"No of epochs\")\n",
    "plt.ylabel(\"Loss&Accyracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "#plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs = model.predict(np.array(testX), batch_size=8)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.metrics.confusion_matrix(testY.argmax(axis=1), predIdxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testY.argmax(axis=1), predIdxs,target_names=['covid', 'normal', 'pneum']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/kaggle/working/model_covid_vs_pneumonia_vs_normal.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('/kaggle/input/model-pneumonia-vs-covidh5/model_pneumonia_vs_covid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 14,747,650\n",
      "Trainable params: 2,392,770\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Activation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = norm_path + norm_files[0]\n",
    "# norm_img = cv2.imread(img_path)\n",
    "# norm_img = cv2.cvtColor(norm_img, cv2.COLOR_BGR2RGB)\n",
    "# norm_img = cv2.resize(norm_img, (224, 224))\n",
    "# norm_img = np.expand_dims(norm_img,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_activation_map(ind,path,files) :\n",
    "    \n",
    "    img_path =  path + files[ind]\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    \n",
    "    predict = model.predict(img)\n",
    "    target_class = np.argmax(predict[0])\n",
    "    last_conv = model.get_layer('block5_conv3')\n",
    "    grads = K.gradients(model.output[:,target_class],last_conv.output)[0]\n",
    "    pooled_grads = K.mean(grads,axis=(0,1,2))\n",
    "    iterate = K.function([model.input],[pooled_grads,last_conv.output[0]])\n",
    "    pooled_grads_value,conv_layer_output = iterate([img])\n",
    "    \n",
    "    for i in range(512):\n",
    "        conv_layer_output[:,:,i] *= pooled_grads_value[i]\n",
    "    \n",
    "    heatmap = np.mean(conv_layer_output,axis=-1)\n",
    "    \n",
    "    for x in range(heatmap.shape[0]):\n",
    "        for y in range(heatmap.shape[1]):\n",
    "            heatmap[x,y] = np.max(heatmap[x,y],0)\n",
    "    heatmap = np.maximum(heatmap,0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    plt.imshow(heatmap)\n",
    "#     output_path_heatmap = '/kaggle/working/output_images/' + files[ind] + 'heatmap.jpeg'\n",
    "#     plt.imsave(output_path_heatmap,heatmap)\n",
    "    \n",
    "    img_gray = cv2.cvtColor(img[0], cv2.COLOR_BGR2GRAY)\n",
    "    upsample = cv2.resize(heatmap, (224,224))\n",
    "    # plt.imshow(upsample,alpha=0.5)\n",
    "    # plt.imshow(img_gray)\n",
    "    #plt.imshow(upsample * img_gray)\n",
    "    output_path_gradcam = '/kaggle/working/' + files[ind] + 'gradcam.jpeg'\n",
    "    plt.imsave(output_path_gradcam,upsample * img_gray)\n",
    "    \n",
    "    #plt.show()\n",
    "    \n",
    "    #return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pne_path\n",
    "files = pne_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_class_activation_map(5,path,files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input/kaggle-covid-xray/kaggle_covid/pneumonia/person1395_bacteria_3544.jpeg'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path + files[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.rmtree('/kaggle/working/output_images/')\n",
    "os.remo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = covid_path + covid_files[1]\n",
    "# covid_img = cv2.imread(img_path)\n",
    "# covid_img = cv2.cvtColor(covid_img, cv2.COLOR_BGR2RGB)\n",
    "# covid_img = cv2.resize(covid_img, (224, 224))\n",
    "# covid_img = np.expand_dims(covid_img,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covid_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict = model.predict(norm_img)\n",
    "# print(decode_predictions(predict,top=3))\n",
    "# target_class = np.argmax(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(norm_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_class = np.argmax(predict[0])\n",
    "# target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Target Class is covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last_conv = model.get_layer('block5_conv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grads = K.gradients(model.output[:,0],last_conv.output)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooled_grads = K.mean(grads,axis=(0,1,2))\n",
    "# iterate = K.function([model.input],[pooled_grads,last_conv.output[0]])\n",
    "# pooled_grads_value,conv_layer_output = iterate([covid_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(512):\n",
    "#     conv_layer_output[:,:,i] *= pooled_grads_value[i]\n",
    "# heatmap = np.mean(conv_layer_output,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(heatmap.shape[0]):\n",
    "#     for y in range(heatmap.shape[1]):\n",
    "#         heatmap[x,y] = np.max(heatmap[x,y],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap = np.maximum(heatmap,0)\n",
    "# heatmap /= np.max(heatmap)\n",
    "# plt.imshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_gray = cv2.cvtColor(norm_img[0], cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample = cv2.resize(heatmap, (224,224))\n",
    "# plt.imshow(upsample,alpha=0.5)\n",
    "# plt.imshow(img_gray)\n",
    "plt.imshow(upsample * img_gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample = cv2.resize(heatmap, (224,224))\n",
    "# plt.imshow(upsample,alpha=0.5)\n",
    "# plt.imshow(img_gray)\n",
    "plt.imshow(upsample * img_gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
