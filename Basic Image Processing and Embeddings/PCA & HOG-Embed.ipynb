{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s0c02nj/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Lambda,subtract,GlobalMaxPooling2D,Dense,GlobalAveragePooling2D, concatenate, Activation\n",
    "from keras.applications.mobilenet import MobileNet as Net\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge\n",
    "from keras.optimizers import Adam\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "#from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import time\n",
    "import glob\n",
    "\n",
    "ALPHA = 0.7 # Triplet Loss Parameter\n",
    "\n",
    "from keras.layers import Input,Lambda,subtract,GlobalMaxPooling2D,Dense,GlobalAveragePooling2D,concatenate,Activation\n",
    "from keras.applications.xception import Xception as Net\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random as rn\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(3)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_array(image):\n",
    "    img = cv2.resize(image, (128, 128)) \n",
    "    img1=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    x_train = np.array([img1])\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_path_to_array(image_path):\n",
    "    img1 = cv2.imread(image_path, 1)\n",
    "    return img_to_array(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_database_tr(location):\n",
    "    database = {}\n",
    "\n",
    "    # load all the images of individuals to recognize into the database\n",
    "    for file in glob.glob(location):\n",
    "        identity = os.path.splitext(os.path.basename(file))[0].strip('NISDCC-_6g')\n",
    "        #print (identity)\n",
    "        database[identity] = img_path_to_array(file)\n",
    "\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_arrays = prepare_database_tr('/Users/s0c02nj/Desktop/Dataset-AxisBankAI/final_database_sign/training/*.PNG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125808954239\n"
     ]
    }
   ],
   "source": [
    "triplet_str_tr=[]\n",
    "\n",
    "t1= time.time()\n",
    "for i in range(1,13):\n",
    "    for ja in range(1,6):\n",
    "        for k in range(23,52):\n",
    "             for jn in range(1,6):\n",
    "                    for jp in range(1,6):\n",
    "                        #print (i,ja,k,jn,jp)\n",
    "                        if (jp!=ja):\n",
    "                            \n",
    "                            if(i<10):\n",
    "                                a='00'+ str(i)+'_00'+str(i)+'_00'+str(ja)\n",
    "                                b='00'+ str(i) +'_00'+str(i)+'_00'+str(jp)\n",
    "                                c='0'+str(k)+'_00'+str(i)+'_00'+str(jn)\n",
    "                            else:\n",
    "                                a='0'+str(i)+'_0'+str(i)+'_00'+str(ja)\n",
    "                                b='0'+str(i)+'_0'+str(i)+'_00'+str(jp)\n",
    "                                c='0'+str(k)+'_0'+str(i)+'_00'+str(jn)\n",
    "                            \n",
    "                            x= (a,b,c)\n",
    "                            triplet_str_tr.append(x)\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "t2=time.time()\n",
    "\n",
    "print (t2-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_tr=[]\n",
    "positive_tr=[]\n",
    "negative_tr=[]\n",
    "\n",
    "for img_name in triplet_str_tr:\n",
    "    anchor_tr.append(train_image_arrays[img_name[0]])\n",
    "    positive_tr.append(train_image_arrays[img_name[1]])\n",
    "    negative_tr.append(train_image_arrays[img_name[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a_tr=np.array(anchor_tr).reshape((len(anchor_tr), 128*128))\n",
    "x_p_tr=np.array(positive_tr).reshape((len(positive_tr),128*128))\n",
    "x_n_tr=np.array(negative_tr).reshape((len(negative_tr),128*128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c=np.vstack((x_a_tr,x_p_tr,x_n_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=700, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=700)\n",
    "pca.fit(x_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9204018049071174"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting PCA features\n",
    "pca_anc_tr= pca.transform(x_a_tr)\n",
    "pca_pos_tr= pca.transform(x_p_tr)\n",
    "pca_neg_tr= pca.transform(x_n_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Unique Identification for training set\n",
    "#Creating Unique Identification for test set embedding\n",
    "pos_feat=np.zeros((len(x_a_tr),700))\n",
    "neg_feat=np.zeros((len(x_a_tr),700))\n",
    "\n",
    "for i in range(0,len(x_a_tr)):\n",
    "    pos_feat[i]= pca_anc_tr[i]-pca_pos_tr[i]\n",
    "    neg_feat[i]= pca_anc_tr[i]-pca_neg_tr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_arr=np.vstack((pos_feat,neg_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_Y = [0]*len(pos_feat)\n",
    "#makes that no of ones as the len of the item given\n",
    "neg_Y = [1]*len(neg_feat)\n",
    "#rowwise appends the two arrays\n",
    "train_y=np.append(pos_Y, neg_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s0c02nj/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(comb_arr, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(random_state=0)\n",
    "log_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print (recall_score(y_test, log_model.predict(x_test)))\n",
    "print (precision_score(y_test, log_model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6931,    0],\n",
       "       [   0, 6989]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=log_model.predict(x_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='/Users/s0c02nj/Desktop/Dataset-AxisBankAI/final_database_sign/test/genuines/NFI-08402084.png'\n",
    "#image_id = 'souradip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_org= img_path_to_array(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path1='/Users/s0c02nj/Desktop/Dataset-AxisBankAI/final_database_sign/test/forgeries/NFI-04901084.png'\n",
    "input_img_org2=img_path_to_array(image_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=np.resize(input_img_org,(1,128*128))\n",
    "img2=np.resize(input_img_org2,(1,128*128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1=pca.transform(img1)\n",
    "i2=pca.transform(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=i1-i2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.predict(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86498929, 0.13501071]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.predict_proba(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_model = RandomForestClassifier(n_estimators=300, max_depth=10,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = np.arange(1, 101)\n",
    "missing_ids = np.array([5, 13, 25, 32, 34, 36, 38, 40, 48, 50, 52, 57, 60, 61, 65, 76, 78, 81, 82, 87, 95])\n",
    "ids_available = np.array(list((set(all_ids)-set(missing_ids))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_formatted=[]\n",
    "for i in range(1,13):\n",
    "    if (i<10):\n",
    "        new_j='0'+str(i)\n",
    "    else:\n",
    "        new_j=str(i)\n",
    "    j_formatted.append(new_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_formatted=[]\n",
    "for i in ids_available:\n",
    "    if (i<10):\n",
    "        new_i='00'+str(i)\n",
    "    elif(9<i<100):\n",
    "        new_i='0'+str(i)\n",
    "    else:\n",
    "        new_i= str(i)\n",
    "    i_formatted.append(new_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_formatted=[]\n",
    "for i in range(3,101):\n",
    "    if (i<10):\n",
    "        new_f='00'+str(i)\n",
    "    elif(9<i<100):\n",
    "        new_f='0'+str(i)\n",
    "    else:\n",
    "        new_f= str(i)\n",
    "    f_formatted.append(new_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_test_comb=[]\n",
    "for i in i_formatted:\n",
    "    for f in f_formatted:\n",
    "        for ja in j_formatted:\n",
    "            for jn in j_formatted[0:6]:\n",
    "                for jp in j_formatted:\n",
    "                    if (jp!=ja):\n",
    "                        a=i+ja+i\n",
    "                        p=i+jp+i\n",
    "                        n=f+jn+i\n",
    "                        triplet_test=(a,p,n)\n",
    "                        triplet_test_comb.append(triplet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_dict(location):\n",
    "    database = {}\n",
    "\n",
    "    # load all the images of individuals to recognize into the database\n",
    "    for file in glob.glob(location):\n",
    "        identity = os.path.splitext(os.path.basename(file))[0].strip('NFI-')\n",
    "        #print (identity)\n",
    "        database[identity] = img_path_to_array(file)\n",
    "\n",
    "    return database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_genuine_dict = prepare_test_dict('/Users/s0c02nj/Desktop/Dataset-AxisBankAI/final_database_sign/test/genuines/*')\n",
    "test_forgery_dict = prepare_test_dict('/Users/s0c02nj/Desktop/Dataset-AxisBankAI/final_database_sign/test/forgeries/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_triplet_test_id=[]\n",
    "for i in range(0,len(triplet_test_comb)):\n",
    "    if ((triplet_test_comb[i][0] in test_genuine_dict.keys()) and (triplet_test_comb[i][1] in test_genuine_dict.keys())and (triplet_test_comb[i][2] in test_forgery_dict.keys())):\n",
    "        final_triplet_test_id.append(triplet_test_comb[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_test=[]\n",
    "positive_test=[]\n",
    "negative_test=[]\n",
    "\n",
    "for img_name in final_triplet_test_id:\n",
    "    anchor_test.append(test_genuine_dict[img_name[0]])\n",
    "    positive_test.append(test_genuine_dict[img_name[1]])\n",
    "    negative_test.append(test_forgery_dict[img_name[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a_test=np.array(anchor_test).reshape((len(anchor_test), 128*128))\n",
    "x_p_test=np.array(positive_test).reshape((len(positive_test),128*128))\n",
    "x_n_test=np.array(negative_test).reshape((len(negative_test),128*128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Text Features\n",
    "x_c_test=np.vstack((x_a_test,x_p_test,x_n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_anc_test= pca.transform(x_a_test)\n",
    "pca_pos_test= pca.transform(x_p_test)\n",
    "pca_neg_test= pca.transform(x_n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca_anc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_feat_test=np.zeros((len(pca_anc_test),700))\n",
    "neg_feat_test=np.zeros((len(pca_anc_test),700))\n",
    "\n",
    "for i in range(0,len(pca_anc_test)):\n",
    "    pos_feat_test[i]= pca_anc_test[i]-pca_pos_test[i]\n",
    "    neg_feat_test[i]= pca_anc_test[i]-pca_neg_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_Y_test = [0]*len(pos_feat_test)\n",
    "#makes that no of ones as the len of the item given\n",
    "neg_Y_test = [1]*len(neg_feat_test)\n",
    "#rowwise appends the two arrays\n",
    "test_y=np.append(pos_Y_test, neg_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat=np.vstack((pos_feat_test,neg_feat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forest_model.score(test_feat,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39822322322322323\n",
      "0.5267286749859322\n"
     ]
    }
   ],
   "source": [
    "print (recall_score(test_y, log_model.predict(test_feat)))\n",
    "print (precision_score(test_y, log_model.predict(test_feat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a_tr=np.array(anchor_tr).reshape((len(anchor_tr), 200,200))\n",
    "x_p_tr=np.array(positive_tr).reshape((len(positive_tr),200,200))\n",
    "x_n_tr=np.array(negative_tr).reshape((len(negative_tr),200,200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_feature_array(image_list):\n",
    "    hog_feat_arr=np.zeros((len(image_list),20736))\n",
    "    from skimage import feature\n",
    "    for i in range(0,len(image_list)):\n",
    "        H = feature.hog(image_list[i], orientations=9, pixels_per_cell=(8, 8),\n",
    "                cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L2\")\n",
    "        hog_feat_arr[i]=H\n",
    "        \n",
    "    return hog_feat_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting HOG Embeddings\n",
    "x_a_hog= get_hog_feature_array(x_a_tr)\n",
    "x_p_hog= get_hog_feature_array(x_p_tr)\n",
    "x_n_hog= get_hog_feature_array(x_n_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34800, 20736)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_a_hog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Unique Identification for training set\n",
    "#Creating Unique Identification for test set embedding\n",
    "pos_feat_hog=np.zeros((len(x_a_tr),20736))\n",
    "neg_feat_hog=np.zeros((len(x_n_tr),20736))\n",
    "\n",
    "for i in range(0,len(x_a_tr)):\n",
    "    pos_feat_hog[i]= x_a_hog[i]-x_p_hog[i]\n",
    "    neg_feat_hog[i]= x_a_hog[i]-x_n_hog[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_arr_hog=np.vstack((pos_feat_hog,neg_feat_hog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_Y_hog = [0]*len(pos_feat_hog)\n",
    "#makes that no of ones as the len of the item given\n",
    "neg_Y_hog = [1]*len(neg_feat_hog)\n",
    "#rowwise appends the two arrays\n",
    "train_y_hog=np.append(pos_Y_hog, neg_Y_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train_hog, x_test_hog, y_train_hog, y_test_hog = train_test_split(comb_arr_hog, train_y_hog, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model_hog = LogisticRegression(random_state=0)\n",
    "log_model_hog.fit(x_train_hog,y_train_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_hog.score(x_test_hog,y_test_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print (recall_score(y_test_hog, log_model_hog.predict(x_test_hog)))\n",
    "print (precision_score(y_test_hog, log_model_hog.predict(x_test_hog)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='/Users/s0c02nj/Desktop/Dataset-AxisBankAI/final_database_sign/test/genuines/NFI-08402084.png'\n",
    "#image_id = 'souradip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_org= img_path_to_array(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path1='/Users/s0c02nj/Desktop/Dataset-AxisBankAI/final_database_sign/test/forgeries/NFI-00304046.png'\n",
    "input_img_org2=img_path_to_array(image_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=np.resize(input_img_org,(200,200))\n",
    "img2=np.resize(input_img_org2,(200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "i1 = feature.hog(img1, orientations=9, pixels_per_cell=(8, 8),\n",
    "                cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L2\")\n",
    "\n",
    "i2= feature.hog(img2, orientations=9, pixels_per_cell=(8, 8),\n",
    "                cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1.resize(1,len(i1))\n",
    "i2.resize(1,len(i2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=i1-i2\n",
    "#diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_hog.predict(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9871637, 0.0128363]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_hog.predict_proba(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
